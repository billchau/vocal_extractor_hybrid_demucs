{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08VoRVmTmZ-r"
      },
      "source": [
        "\n",
        "# Extract vocal from song\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. How to use\n",
        "1. Run 1 - 3 to install necessary dependencies.\n",
        "2. Edit and run 4A to download a song\n",
        "3. Edit and run 4B to update the input output file\n",
        "4. Run step after 4B to get the vocal.\n",
        "\n",
        "If you need to extract multiple vocal clips,\n",
        "1. Repeat step 2 - 4 when you need to download song from youtube\n",
        "2. Repeat step 3 - 4 when you uploaded all files to Google colab"
      ],
      "metadata": {
        "id": "yWRChsgPvsHb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JM9juZKmZ-t"
      },
      "source": [
        "## 1. Original of the code\n",
        "\n",
        "The code is modified from the code below\n",
        "https://pytorch.org/audio/main/tutorials/hybrid_demucs_tutorial.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Visd1DDamZ-u"
      },
      "source": [
        "## 2. Preparation\n",
        "\n",
        "First, we install the necessary dependencies. The first requirement is\n",
        "``torchaudio`` and ``torch``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iCNNmQ0pmZ-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77c6823-bba7-4fc4-812c-6fc31bfed8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "0.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgn2Z89emZ-w"
      },
      "source": [
        "In addition to ``torchaudio``, ``mir_eval`` is required to perform\n",
        "signal-to-distortion ratio (SDR) calculations. To install ``mir_eval``\n",
        "please use ``pip3 install mir_eval``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall -y torch torchvision torchaudio\n",
        "!pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
        "!pip3 install mir_eval"
      ],
      "metadata": {
        "id": "DnnBg_S-nuD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pCYJXNmdmZ-w"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "from torchaudio.utils import download_asset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS\n",
        "    from mir_eval import separation\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    try:\n",
        "        import google.colab\n",
        "\n",
        "        print(\n",
        "            \"\"\"\n",
        "            To enable running this notebook in Google Colab, install nightly\n",
        "            torch and torchaudio builds by adding the following code block to the top\n",
        "            of the notebook before running it:\n",
        "            !pip3 uninstall -y torch torchvision torchaudio\n",
        "            !pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
        "            !pip3 install mir_eval\n",
        "            \"\"\"\n",
        "        )\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgvT7ozPmZ-x"
      },
      "source": [
        "## 3. Construct the pipeline\n",
        "\n",
        "Pre-trained model weights and related pipeline components are bundled as\n",
        ":py:func:`torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS`. This is a\n",
        ":py:class:`torchaudio.models.HDemucs` model trained on\n",
        "[MUSDB18-HQ](https://zenodo.org/record/3338373)_ and additional\n",
        "internal extra training data.\n",
        "This specific model is suited for higher sample rates, around 44.1 kHZ\n",
        "and has a nfft value of 4096 with a depth of 6 in the model implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "IT47AsBEmZ-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2e7fc4-9ca6-4f4e-fbf2-76ecc565ce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample rate: 44100\n"
          ]
        }
      ],
      "source": [
        "bundle = HDEMUCS_HIGH_MUSDB_PLUS\n",
        "\n",
        "model = bundle.get_model()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "sample_rate = bundle.sample_rate\n",
        "# sample_rate = 48000\n",
        "\n",
        "print(f\"Sample rate: {sample_rate}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4A. Download song from youtube for testing\n",
        "Run the codes below again if you want to download multiple songs.\n",
        "\n",
        "Make sure the audio channel is stereo."
      ],
      "metadata": {
        "id": "lrRTYxdklGbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up youtube-dl\n",
        "try: import youtube_dl\n",
        "except:\n",
        "    !pip3 install youtube-dl\n",
        "\n",
        "import youtube_dl\n",
        "import google\n"
      ],
      "metadata": {
        "id": "ik6_NHunlU6F"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download one song\n",
        "\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=CinYtExTp5o\"\n",
        "!youtube-dl --ignore-errors --format bestaudio --extract-audio --audio-format wav --audio-quality 0 --output \"music_1.%(ext)s\" {url}\n",
        "# !youtube-dl --ignore-errors --format bestaudio --extract-audio --audio-format wav --audio-quality 0 --output \"./%(title)s.%(ext)s\" {url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS0nfJD3mh3N",
        "outputId": "ff0445f7-6cd9-45a0-e735-6fd02df29316"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] CinYtExTp5o: Downloading webpage\n",
            "[download] Destination: music_1.webm\n",
            "\u001b[K[download] 100% of 3.55MiB in 00:59\n",
            "[ffmpeg] Destination: music_1.wav\n",
            "Deleting original file music_1.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download playlist\n",
        "\n",
        "# url = \"https://www.youtube.com/playlist?list=PL4wE0_pD37K-NBALqjTGOMhcemYEdzCbB\"\n",
        "# !youtube-dl --ignore-errors --format bestaudio --extract-audio --audio-format wav --audio-quality 0 --output \"./downloads/%(title)s.%(ext)s\" --yes-playlist {url}"
      ],
      "metadata": {
        "id": "AuaJPf_dmdCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4B. Setup hyperparameters\n",
        "Run the codes below again if you want to extract multiple songs.\n",
        "\n",
        "Make sure the audio channel is stereo.\n",
        "\n",
        "If you need to extract large amount of the songs, write the for loop yourself."
      ],
      "metadata": {
        "id": "F-b8ciZDWzX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = f\"music_1.wav\"\n",
        "output_file = f\"music_1_vocal.wav\""
      ],
      "metadata": {
        "id": "8J8cm7qvXI_J"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnoAaTMamZ-y"
      },
      "source": [
        "## 5. Configure the application function\n",
        "\n",
        "Because ``HDemucs`` is a large and memory-consuming model it is\n",
        "very difficult to have sufficient memory to apply the model to\n",
        "an entire song at once. To work around this limitation,\n",
        "obtain the separated sources of a full song by\n",
        "chunking the song into smaller segments and run through the\n",
        "model piece by piece, and then rearrange back together.\n",
        "\n",
        "When doing this, it is important to ensure some\n",
        "overlap between each of the chunks, to accommodate for artifacts at the\n",
        "edges. Due to the nature of the model, sometimes the edges have\n",
        "inaccurate or undesired sounds included.\n",
        "\n",
        "We provide a sample implementation of chunking and arrangement below. This\n",
        "implementation takes an overlap of 1 second on each side, and then does\n",
        "a linear fade in and fade out on each side. Using the faded overlaps, I\n",
        "add these segments together, to ensure a constant volume throughout.\n",
        "This accommodates for the artifacts by using less of the edges of the\n",
        "model outputs.\n",
        "\n",
        "<img src=\"https://download.pytorch.org/torchaudio/tutorial-assets/HDemucs_Drawing.jpg\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "h3XpCIV0mZ-z"
      },
      "outputs": [],
      "source": [
        "from torchaudio.transforms import Fade\n",
        "\n",
        "\n",
        "def separate_sources(\n",
        "        model,\n",
        "        mix,\n",
        "        segment=10.,\n",
        "        overlap=0.1,\n",
        "        device=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Apply model to a given mixture. Use fade, and add segments together in order to add model segment by segment.\n",
        "\n",
        "    Args:\n",
        "        segment (int): segment length in seconds\n",
        "        device (torch.device, str, or None): if provided, device on which to\n",
        "            execute the computation, otherwise `mix.device` is assumed.\n",
        "            When `device` is different from `mix.device`, only local computations will\n",
        "            be on `device`, while the entire tracks will be stored on `mix.device`.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = mix.device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "\n",
        "    batch, channels, length = mix.shape\n",
        "\n",
        "    chunk_len = int(sample_rate * segment * (1 + overlap))\n",
        "    start = 0\n",
        "    end = chunk_len\n",
        "    overlap_frames = overlap * sample_rate\n",
        "    fade = Fade(fade_in_len=0, fade_out_len=int(overlap_frames), fade_shape='linear')\n",
        "\n",
        "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
        "\n",
        "    while start < length - overlap_frames:\n",
        "        chunk = mix[:, :, start:end]\n",
        "        with torch.no_grad():\n",
        "            out = model.forward(chunk)\n",
        "        out = fade(out)\n",
        "        final[:, :, :, start:end] += out\n",
        "        if start == 0:\n",
        "            fade.fade_in_len = int(overlap_frames)\n",
        "            start += int(chunk_len - overlap_frames)\n",
        "        else:\n",
        "            start += chunk_len\n",
        "        end += chunk_len\n",
        "        if end >= length:\n",
        "            fade.fade_out_len = 0\n",
        "    return final\n",
        "\n",
        "\n",
        "def plot_spectrogram(stft, title=\"Spectrogram\"):\n",
        "    magnitude = stft.abs()\n",
        "    spectrogram = 20 * torch.log10(magnitude + 1e-8).numpy()\n",
        "    figure, axis = plt.subplots(1, 1)\n",
        "    img = axis.imshow(spectrogram, cmap=\"viridis\", vmin=-60, vmax=0, origin=\"lower\", aspect=\"auto\")\n",
        "    figure.suptitle(title)\n",
        "    plt.colorbar(img, ax=axis)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcPw2ULLmZ-z"
      },
      "source": [
        "## 6. Run Model\n",
        "\n",
        "Finally, we run the model and store the separate source files in a\n",
        "directory\n",
        "\n",
        "As a test song, we will be using A Classic Education by NightOwl from\n",
        "MedleyDB (Creative Commons BY-NC-SA 4.0). This is also located in\n",
        "[MUSDB18-HQ](https://zenodo.org/record/3338373)_ dataset within\n",
        "the ``train`` sources.\n",
        "\n",
        "In order to test with a different song, the variable names and urls\n",
        "below can be changed alongside with the parameters to test the song\n",
        "separator in different ways.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "ivWEjpeVmZ-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b7fd27-1bda-46b6-fd24-55eaaf978d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track\n"
          ]
        }
      ],
      "source": [
        "# We download the audio file from our storage. Feel free to download another file and use audio from a specific path\n",
        "# SAMPLE_SONG = download_asset(\"tutorial-assets/hdemucs_mix.wav\")\n",
        "SAMPLE_SONG = input_file\n",
        "waveform, sample_rate = torchaudio.load(SAMPLE_SONG)  # replace SAMPLE_SONG with desired path for different song\n",
        "waveform = waveform.to(device)\n",
        "mixture = waveform\n",
        "\n",
        "info = torchaudio.info(SAMPLE_SONG)\n",
        "encoding= info.encoding\n",
        "bits_per_sample = info.bits_per_sample\n",
        "\n",
        "# parameters\n",
        "segment: int = 10\n",
        "overlap = 0.1\n",
        "\n",
        "print(\"Separating track\")\n",
        "\n",
        "ref = waveform.mean(0)\n",
        "waveform = (waveform - ref.mean()) / ref.std()  # normalization\n",
        "\n",
        "sources = separate_sources(\n",
        "    model,\n",
        "    waveform[None],\n",
        "    device=device,\n",
        "    segment=segment,\n",
        "    overlap=overlap,\n",
        ")[0]\n",
        "sources = sources * ref.std() + ref.mean()\n",
        "\n",
        "sources_list = model.sources\n",
        "sources = list(sources)\n",
        "\n",
        "audios = dict(zip(sources_list, sources))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def inspect_file(path):\n",
        "    print(\"-\" * 10)\n",
        "    print(\"Source:\", path)\n",
        "    print(\"-\" * 10)\n",
        "    print(f\" - File size: {os.path.getsize(path)} bytes\")\n",
        "    print(f\" - {torchaudio.info(path)}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "qH_M5sVUCexv"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = output_file\n",
        "# torchaudio.save(path, waveform, sample_rate)\n",
        "torchaudio.save(\n",
        "    path, \n",
        "    audios[\"vocals\"], \n",
        "    sample_rate=sample_rate,\n",
        "    encoding=encoding,\n",
        "    bits_per_sample = bits_per_sample\n",
        "  )\n",
        "inspect_file(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "m0JcbgZDCTHv",
        "outputId": "2b2b9c7d-316d-4808-8ca7-103fafaf185d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-ffe057daee36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# torchaudio.save(path, waveform, sample_rate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m torchaudio.save(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maudios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchaudio/backend/sox_io_backend.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(filepath, src, sample_rate, channels_first, compression, format, encoding, bits_per_sample)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_deprecation_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             torchaudio.lib._torchaudio_sox.save_audio_fileobj(\n\u001b[0;32m--> 418\u001b[0;31m                 \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Internal Error: unexpected encoding value: OPUS"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_file(f\"music_1.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyxtprjerwzb",
        "outputId": "3de9f865-9d0e-4171-9c24-b54ffe7ac343"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Source: music_1.wav\n",
            "----------\n",
            " - File size: 40989058 bytes\n",
            " - AudioMetaData(sample_rate=48000, num_frames=10247245, num_channels=2, bits_per_sample=16, encoding=PCM_S)\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}